import os
import openai
from groq import Groq
import json
from transformers import pipeline

# âœ… Gestion hybride des clÃ©s API
try:
    from dotenv import load_dotenv
    load_dotenv()
except:
    pass

try:
    import streamlit as st
    os.environ["GROQ_API_KEY"] = st.secrets["GROQ_API_KEY"]
    os.environ["OPENAI_API_KEY"] = st.secrets["OPENAI_API_KEY"]
except:
    pass

# ðŸ”Š Transcription audio avec lâ€™API Groq (Whisper)
def speech_to_text(audio_path: str, language: str = "fr") -> str:
    client = Groq(api_key=os.environ["GROQ_API_KEY"])
    with open(audio_path, "rb") as file:
        transcription = client.audio.transcriptions.create(
            file=file,
            model="whisper-large-v3-turbo",
            prompt="Extrait le texte de l'audio de la maniÃ¨re la plus factuelle possible",
            response_format="text",
            timestamp_granularities=["word", "segment"],
            language=language,
            temperature=0.0
        )
    return transcription

# ðŸ–¼ GÃ©nÃ©ration dâ€™image via OpenAI
def generate_image(prompt: str) -> str:
    openai.api_key = os.environ["OPENAI_API_KEY"]
    response = openai.Image.create(
        prompt=prompt,
        n=1,
        size="512x512"
    )
    return response["data"][0]["url"]

# ðŸ’­ DÃ©tection dâ€™Ã©motion via modÃ¨le HuggingFace
emotion_classifier = pipeline("sentiment-analysis", model="j-hartmann/emotion-english-distilroberta-base")

def detect_emotion(text: str) -> str:
    result = emotion_classifier(text)
    return max(result, key=lambda x: x['score'])['label']

